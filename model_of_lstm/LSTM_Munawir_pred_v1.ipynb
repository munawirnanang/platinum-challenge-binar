{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# masukan model\n",
    "loaded_model = load_model(r'lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras dari library tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import re\n",
    "\n",
    "# buat fungsi pred_sentiment\n",
    "def pred_sentiment(text):\n",
    "    # lakukan subtitusi jika karakter tidak termasuk di a-zA-Z0-9. maka dilakukan perubahan menjadi string kosong\n",
    "    clean_text = re.sub(r'[^a-zA-Z0-9. ]', '', text)\n",
    "    # ubah menjadi lowercase\n",
    "    clean_text = clean_text.lower()\n",
    "    # masukan ke variable text_new\n",
    "    text_new = [clean_text]\n",
    "    \n",
    "    # Memecah kalimat menjadi kata.  \n",
    "    # saring text yang mengandung !\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\n",
    "    # ubah text menjadi lowercase\n",
    "    tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
    "    # setiap kalimat pada df['text'] diubah ke dalam bentuk tokenizer\n",
    "    tokenizer.fit_on_texts(text_new)\n",
    "    # ubah kata pada data df['text'] menjadi urutan integer\n",
    "    sekuens_x = tokenizer.texts_to_sequences(text_new)\n",
    "    # ubah urutan integer pada sequences_x ke dalam array 2D.\n",
    "    # maxlen=None. maksimum panjang array akan disesuaikan dengan kalimat yang memiliki kumpulan kata terpanjang pada valiable sekuens_x\n",
    "    # kalimat yang tidak memiliki kumpulan kata yang panjang akan di berikan pading\n",
    "    padded_x = pad_sequences(sekuens_x, maxlen=None)\n",
    "\n",
    "    # melakukan prediksi dengan menggunakan model yang telah dimuat. padded_x merupakan data yang akan di lakukan prediksi, batch_size adalah ukuran batch saat melakukan prediksi\n",
    "    classes = loaded_model.predict(padded_x, batch_size=10)\n",
    "\n",
    "    return classes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat fungsi pred(classes)\n",
    "def pred(classes):\n",
    "    # lakukan pencetakan berdasarkan nilai maksimum dari array classes\n",
    "    if classes[0] == classes.max():\n",
    "        print('negative')\n",
    "    if classes[1] == classes.max():\n",
    "        print('neutral')\n",
    "    if classes[2] == classes.max():\n",
    "        print('positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 325ms/step\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "# masukan string text\n",
    "string = \"pakai BNA pasti untung, ga rugi deh\"\n",
    "# panggil fungsi pred_sentiment dan masukan variabel string ke dalam fungsi \n",
    "classes = pred_sentiment(string)\n",
    "# panggil fungsi pred dan amsukan variable string\n",
    "pred(classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
