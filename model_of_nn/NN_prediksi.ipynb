{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_text = \"warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import text_preprocessing as tp\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#load train dataset\n",
    "df_train = pd.read_csv('train_preprocess.tsv', sep='\\t',header = None)\n",
    "#df_train = pd.read_csv('/content/train_preprocess.tsv', sep='\\t', header=None)\n",
    "df_data = df_train.rename(columns={0: 'Text',1: 'Sentimen'})\n",
    "\n",
    "#load kamus alay dataset\n",
    "kamus_alay = pd.read_csv('new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "#kamus_alay = pd.read_csv('/content/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "kamus_alay = kamus_alay.rename(columns={0: 'original', 1: 'replacement'})\n",
    "\n",
    "id_stopword_dict = pd.read_csv('stopwordbahasa.csv', header=None)\n",
    "#id_stopword_dict = pd.read_csv('/content/stopwordbahasa.csv', header=None)\n",
    "id_stopword_dict = id_stopword_dict.rename(columns={0: 'stopword'})\n",
    "\n",
    "\n",
    "# Define the preprocessing function\n",
    "#text cleansing with regex\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def hapus_karakter_ga_penting(text):\n",
    "    text = re.sub('\\n',' ',text) # Hapus enter\n",
    "    text = re.sub('nya|deh|sih',' ',text) # Hapus stopwords tambahan\n",
    "    text = re.sub('RT',' ',text) # Hapus RT\n",
    "    text = re.sub('USER',' ',text) # Hapus USER\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', ' ',text) # Hapus URL\n",
    "    text = re.sub('  +', ' ', text) # Hapus extra spaces\n",
    "    text = re.sub('[^a-zA-Z0-9]', ' ', text) #Hapus non huruf dan angka  \n",
    "    text = re.sub('\\@[a-zA-Z0-9]*', ' ', text) #Hapus non huruf atau apostrophe\n",
    "    text = ' '.join([w for w in text.split() if len(w)>1]) #Hapus huruf tunggal \n",
    "    return text\n",
    "    \n",
    "def hapus_nonhurufangka(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "df_data_map = dict(zip(df_data['Text'], df_data['Sentimen']))\n",
    "def normalisasi_alay(text):\n",
    "    return ' '.join([df_data_map[word] if word in df_data_map else word for word in text.split(' ')])\n",
    "\n",
    "def hapus_stopword(text):\n",
    "    text = ' '.join(['' if word in id_stopword_dict.stopword.values else word for word in text.split(' ')])\n",
    "    text = re.sub('  +', ' ', text) # Hapus extra spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def stemming(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "def cleansing(text):\n",
    "    text = lowercase(text) \n",
    "    text = hapus_nonhurufangka(text) \n",
    "    text = hapus_karakter_ga_penting(text) \n",
    "    text = normalisasi_alay(text) \n",
    "    text = stemming(text) \n",
    "    text = hapus_stopword(text) \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = pickle.load(open(\"feature_New3.sav\", \"rb\"))\n",
    "model_NN = pickle.load(open(\"model_NN3.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = count_vect.transform([cleansing(ori_text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "result = model_NN.predict(text)[0]\n",
    "print(\"Sentiment:\", result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi menggunakan Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !\n",
      "\n",
      "text_new :  warung milik usaha pabrik puluh kenal putih bandung positive padu ahli masak padu kretivitas warung me jikan menu utama bahan menu ayam selera indonesia harga jangkau bletoka kalah asli tegal\n",
      "\n",
      "Sentiment :  positive\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import text_preprocessing\n",
    "\n",
    "# Download the Indonesian stopwords if not already downloaded\n",
    "\n",
    "contoh = \"warung ini dimiliki oleh pengusaha pabrik tahu yang sudah puluhan tahun terkenal membuat tahu putih di bandung . tahu berkualitas , dipadu keahlian memasak , dipadu kretivitas , jadilah warung yang menyajikan menu utama berbahan tahu , ditambah menu umum lain seperti ayam . semuanya selera indonesia . harga cukup terjangkau . jangan lewatkan tahu bletoka nya , tidak kalah dengan yang asli dari tegal !\"\n",
    "preprocessed_text = cleansing(contoh)\n",
    "text_vector = count_vect.transform([preprocessed_text])\n",
    "\n",
    "result = model_NN.predict(text_vector)[0]\n",
    "print(\"text : \", contoh)\n",
    "print(\"\\ntext_new : \", preprocessed_text)\n",
    "print(\"\\nSentiment : \", result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envbinar",
   "language": "python",
   "name": "envbinar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
